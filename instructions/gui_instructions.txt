Instructions for running the GUI:

1. Upload grammar and distribution files using the file selector buttons.
2. Choose which program to run: EDL or GLA
3. Specify the kind of learner you wish to run. There are 2 options for EDL, and 4 for GLA.
4. Supply program-specific arguments
5. To change the output that the program produces, you can change the default settings in the Print Parameters menu.
6. You may also modify other settings, mostly related to efficiency, in the Advanced Options menu.
7. Once all settings have been filled in, click the RUN button to start the program. Output will appear in the text box on the right.

-------------------------
Description of arguments
-------------------------

LEARNER NAME
- This is either EDL or GLA

GRAMMAR FILE
- should be in the same format as provided TS2000Grammar_secondary.txt

DISTRIBUTION FILE
- should be in the same format as provided TS1_Dist.txt

ITERATIONS
- this is the number of passes through the data
- For GLA, reasonable values are around 100-1000 (higher for complex data)
- The batch EDL learner sees every data point at each iteration, so a reasonable number of iterations is around 100
- The online EDL learner sees only 1 data point at each iteration, so a comparable number of iterations is 100*the number of data points

FINAL-EVAL_SAMPLE
-How many samples are used to evaluate in the final evaluation
-Default: 1000

INITIAL BIAS
- Default 0 (GLA starts out with all ranking values at 10, and EDL with all pairwise rankings set to .5)
- Set to 1 if you want to start with a biased initial grammar. The initial ranking will be read from the grammar file. See FileFormats_instructions.txt in the instructions directory for how the the specified numbers will be used by GLA and EDL.

-------------------------
EDL-specific arguments
-------------------------

LEARNER
1 - batch Expectation Driven Learner in Jarosz (2015). Runs the learning function EDL_batch().
2 - online Expectation Driven Learner in Jarosz (2015). Runs the learning function EDL_online().

GRAMMAR SAMPLE SIZE
-this is the number of times that a grammar is sampled during each round of learning
- reasonable values are 50-100

LEARNING RATE (for Online EDL only)
 - How much pairwise ranking probabilities get nudged when there’s an update
 - typical value is something like 0.1

UR LEARNING?
- unchecked: learner uses the provided URs in the Distribution file for learning
- checked: learner has to learn UR features, and these are specified in the UR_FILE

UR FILE
- file that specifies the range of URs and their binary features for each morpheme in the data (Distribution) file
- this file is only consulted if UR LEARNING is checked

PHONO_ITERATIONS
- How many iterations of phonotactic learning (learning without adjusting the URs) should occur
- In order for any UR learning to occur, this value must be less than the value specified for ITERATIONS
- The learner initially sets all UR features to uniform (e.g. 50% probability of each feature value) 
- this value is consulted only if UR_LEARNING is checked

-------------------------
GLA-specific arguments
-------------------------

LEARNER
 EIP - Jarosz (2013)
 RIP - is the original RIP as proposed for Stochastic OT by Boersma (2003)
 RRIP - is what is called RRIP in Jarosz (2013)
 randRIP - baseline model without parsing; when there’s an error it generates a random output as the ‘winner’ for the update.

 GRAMMAR TYPE
 - set this to OT, HG, or ME (maxent)

LEARNING RATE
 - How much constraint ranking/weighting values get nudged when there’s an update
 - typical value is something like 0.1

 NOISE
 - what’s the variance around the ranking/weighting value
 - typical setting is something like 2

 NEGOK?
 - Indicates whether the learner be allowed to use negative weights.

-------------------------
PRINT OPTIONS
-------------------------

PRINT_INPUT?: specifies whether the input to the learner, like the grammar and distribution files, should be printed.

INTERMEDIATE EVAL

PRINT GRAMMAR?: should the current grammar be printed at each evaluation round?
PRINT ACCURACY PER OUTPUT?: should the current grammar’s predictions for each data point be printed at each evaluation round?

EVALUATION FREQ: how often should an intermediate evaluation round be performed?
- In order to not perform any intermediate evaluation, set to the same number as iterations

SAMPLE SIZE: how many samples should be used to evaluate in an intermediate evaluation?

FINAL-EVAL: what should the final evaluation print?

-------------------------
EFFICIENCY OPTIONS
-------------------------

QUIT_EARLY_FREQ: how often should the program check to see if it can quit early?
-Quits if the learner has already learned everything
- In order to never quit early, set to the same number as iterations

SAMPLE_SIZE: how many samples should be used to evaluate whether the learner is done learning?
-The fewer samples, the faster the program, but the greater the risk of quitting before the learner has really finished learning

TREE MAX-DEPTH:
-For EDL, you can override the maximum depth of the tree that stores winners that have previously been calculated for tableau/ranking combinations.
-By default, the maximum depth of the tree is set to 100, but you can reduce the depth to reduce the amount of memory used by the program.
-For very large input files, this may speed up the program.